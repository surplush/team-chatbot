{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b61d369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "\n",
    "openai_embedding=OpenAIEmbeddings(model = 'text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264b1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    return loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68da13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    split_docs = text_splitter.split_documents(_docs)\n",
    "    persist_directory = \"./chroma_db\"\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        split_docs, \n",
    "        OpenAIEmbeddings(model='text-embedding-3-small'),\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee31e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_vector_store(new_docs, persist_directory=\"./chroma_db\"):\n",
    "    # 1. 기존 벡터 저장소 불러오기\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    )\n",
    "\n",
    "    # 2. 문서 분할\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    split_docs = text_splitter.split_documents(new_docs)\n",
    "\n",
    "    # 3. 문서 추가\n",
    "    vectorstore.add_documents(split_docs)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c04695",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = r\"C:\\python workspace\\3-3\\챗봇\\논문\"\n",
    "pdf_files = [f for f in os.listdir(pdf_dir) if f.endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "402e809b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mansr\\AppData\\Local\\Temp\\ipykernel_12092\\3363452400.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "for pdf in pdf_files:\n",
    "    path = os.path.join(pdf_dir, pdf)\n",
    "    sp = load_and_split_pdf(path)\n",
    "    add_to_vector_store(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb6f8af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IEEE Trans. Geosci. Remote Sens., vol. 46, no. 12, pp. 4173–4185, Dec.\n",
      "2008.\n",
      "[48] X. Huang, L. Zhang, and L. Wang,“Evaluation of morphological texture\n",
      "features for mangrove forest mapping and species discrimination using\n",
      "multispectral IKONOS imagery,” IEEE Geosci. Remote Sens. Lett., vol. 6,\n",
      "no. 3, pp. 393–397, Jul. 2009.\n",
      "Junhwa Chi(S’10–M’14) received the B.S. degree in\n",
      "geoinformatic engineering, the second B.S. degree in\n",
      "computer science from Inha University, Incheon,\n",
      "SouthKorea,in2006,theM.S.degreeingeoinformatic\n",
      "engineeringin 2008,and thePh.D.degree in geomatics\n",
      "engineering from the School of Civil Engineering,\n",
      "Purdue University, West Lafayette, IN, USA, in 2013.\n",
      "Currently, he works as a Postdoctoral Scholar with\n",
      "the Center for Spatial Technologies and Remote Sens-\n",
      "ing (CSTARS), Department of Land, Air, and Water\n",
      "Resources, University of California, Davis, CA, USA.\n",
      "His research interests include agricultural/environmental remote sensing applica-\n"
     ]
    }
   ],
   "source": [
    "# load from disk\n",
    "db3 = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "query = \"junhwa chi's paper?\"\n",
    "result = db3.similarity_search(query)\n",
    "print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09418cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mansr\\AppData\\Local\\Temp\\ipykernel_12092\\2887330060.py:19: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-4o\")\n",
      "C:\\Users\\mansr\\AppData\\Local\\Temp\\ipykernel_12092\\2887330060.py:20: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=PROMPT)\n",
      "C:\\Users\\mansr\\AppData\\Local\\Temp\\ipykernel_12092\\2887330060.py:22: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  summary = chain.run(context=context_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**연구대상 및 방법:**\n",
      "이 연구는 한국에서의 사용후핵연료 관리 정책에 대한 대중의 인식과 선호도를 분석하기 위한 목적으로 수행되었습니다. 연구 데이터는 2020년 1월에 전문 조사 기관인 Macromil Embrain을 통해 온라인 설문조사를 통해 수집되었으며, 설문조사 참여자는 성별, 연령, 지역을 고려한 비례층화 표본추출 방법을 통해 선정된 20세에서 59세 사이의 성인 1,000명이었습니다.\n",
      "\n",
      "**연구방법:**\n",
      "연구는 사용후핵연료 관리에 대한 대중의 태도와 선호를 개인 및 세그먼트 수준에서 분석하기 위해 설문조사 데이터를 활용한 통계적 분석을 진행하였습니다. 분석에는 다변량 통계 기법이 적용되어 정책에 대한 대중의 다양한 반응과 인식을 구체적으로 파악하고자 하였습니다.\n",
      "\n",
      "**연구결과:**\n",
      "연구 결과, 대중은 사용후핵연료 저장소의 위험성과 관련하여 부정적인 결과들에 대한 우려를 표명하였으며, 전반적으로 정책에 대한 수용도는 시간이 지남에 따라 감소하는 경향을 보였습니다. 또한, 사용후핵연료 관리에 대한 대중의 인식은 지리적 요인과 밀접하게 관련되어 있으며, 지역별 기상 조건을 고려하여 개별 정책이 마련되고 시행되어야 한다는 점이 강조되었습니다.\n",
      "\n",
      "**제언:**\n",
      "연구는 사용후핵연료 관리 정책의 사회적 합의를 위해서는 대중의 인식과 선호를 반영한 정책 마련이 필요하다고 제언합니다. 또한, 지역적 기상 조건을 고려하여 맞춤형 정책을 수립하고, 정책 결정 과정에서 대중과 전문가 간의 소통을 강화할 필요가 있습니다. 이를 통해 보다 효과적이고 수용 가능한 사용후핵연료 관리 정책을 구현할 수 있을 것입니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "db3 = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "query = \"explain hyungbin moon's 2020 paper\"\n",
    "docs = db3.similarity_search(query, k=15)\n",
    "\n",
    "formatted_docs = [Document(page_content=doc.page_content) for doc in docs]\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "다음은 논문 일부입니다. 이 내용을 바탕으로 석사 논문 내용을 연구대상 및 방법, 연구방법, 연구결과, 제언을 핵심적으로 요약해 주세요.\n",
    "논문 내용:\n",
    "{context}\n",
    "요약:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)\n",
    "context_text = \"\\n\\n\".join([doc.page_content for doc in formatted_docs])\n",
    "summary = chain.run(context=context_text)\n",
    "print(summary, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
